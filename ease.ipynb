{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under ml-latest-small (1).zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ml-latest-small/\n",
      "x ml-latest-small/links.csv\n",
      "x ml-latest-small/tags.csv\n",
      "x ml-latest-small/ratings.csv\n",
      "x ml-latest-small/README.txt\n",
      "x ml-latest-small/movies.csv\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "!python3 -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\n",
    "!tar -xvzf ml-20m-compact.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7481</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enemy Mine (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1046</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Beautiful Thing (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>3535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>American Psycho (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>5669</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bowling for Columbine (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190616</th>\n",
       "      <td>138493</td>\n",
       "      <td>288</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Natural Born Killers (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190617</th>\n",
       "      <td>138493</td>\n",
       "      <td>1748</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dark City (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190618</th>\n",
       "      <td>138493</td>\n",
       "      <td>616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190619</th>\n",
       "      <td>138493</td>\n",
       "      <td>1597</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Conspiracy Theory (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190620</th>\n",
       "      <td>138493</td>\n",
       "      <td>7371</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dogville (2003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190621 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating                         title\n",
       "0           11     7481     5.0             Enemy Mine (1985)\n",
       "1           11     1046     4.5        Beautiful Thing (1996)\n",
       "2           11      616     4.0        Aristocats, The (1970)\n",
       "3           11     3535     2.0        American Psycho (2000)\n",
       "4           11     5669     5.0  Bowling for Columbine (2002)\n",
       "...        ...      ...     ...                           ...\n",
       "190616  138493      288     5.0   Natural Born Killers (1994)\n",
       "190617  138493     1748     5.0              Dark City (1998)\n",
       "190618  138493      616     4.0        Aristocats, The (1970)\n",
       "190619  138493     1597     4.5      Conspiracy Theory (1997)\n",
       "190620  138493     7371     5.0               Dogville (2003)\n",
       "\n",
       "[190621 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./dataset/movies_sample.csv')\n",
    "ratings = pd.read_csv('./dataset/ratings_sample.csv')\n",
    "tags = pd.read_csv('./dataset/tags_sample.csv')\n",
    "df = ratings[['userId', 'movieId', 'rating']]\n",
    "df = df.merge(movies[['movieId', 'title']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>Gregory Peck</td>\n",
       "      <td>1329962459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>need to own</td>\n",
       "      <td>1329962471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>1329962476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>Rome</td>\n",
       "      <td>1329962490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>royalty</td>\n",
       "      <td>1329962474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>138301</td>\n",
       "      <td>109487</td>\n",
       "      <td>ambitious</td>\n",
       "      <td>1423178287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>138301</td>\n",
       "      <td>1089</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>1407271610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>138301</td>\n",
       "      <td>1089</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>1407271608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>138301</td>\n",
       "      <td>109487</td>\n",
       "      <td>Self-Indulgent</td>\n",
       "      <td>1423178219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>138301</td>\n",
       "      <td>1089</td>\n",
       "      <td>thriller</td>\n",
       "      <td>1407271632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId                tag  timestamp_y\n",
       "0        279      916       Gregory Peck   1329962459\n",
       "1        279      916        need to own   1329962471\n",
       "2        279      916    romantic comedy   1329962476\n",
       "3        279      916               Rome   1329962490\n",
       "4        279      916            royalty   1329962474\n",
       "...      ...      ...                ...          ...\n",
       "6269  138301   109487          ambitious   1423178287\n",
       "6270  138301     1089          nonlinear   1407271610\n",
       "6271  138301     1089  Quentin Tarantino   1407271608\n",
       "6272  138301   109487     Self-Indulgent   1423178219\n",
       "6273  138301     1089           thriller   1407271632\n",
       "\n",
       "[6274 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento de ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_users = {user: idx for idx, user in enumerate(df.userId.unique())}\n",
    "map_items = {item: idx for idx, item in enumerate(movies.movieId.unique())}\n",
    "df['userId'] = df['userId'].map(map_users)\n",
    "df['movieId'] = df['movieId'].map(map_items)\n",
    "tags['userId'] = tags['userId'].map(map_users)\n",
    "tags['movieId'] = tags['movieId'].map(map_items)\n",
    "movies['movieId'] = movies['movieId'].map(map_items)\n",
    "\n",
    "map_title = {}\n",
    "\n",
    "for row in df.itertuples():\n",
    "    map_title[row.movieId] = row.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão da base em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# REMOVER DEPOIS\n",
    "#df = df.iloc[:20000]\n",
    "train, test = train_test_split(df, test_size=.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE:\n",
    "  def __init__(self, train: pd.DataFrame, lambda_: float):\n",
    "    \"\"\"\n",
    "    Initialize the EASE (Embarrassingly Shallow Autoencoder) model for collaborative filtering.\n",
    "    \n",
    "    Args:\n",
    "        train (pd.DataFrame): Training data containing user-item interactions\n",
    "                            Expected columns: ['userId', 'movieId']\n",
    "        lambda_ (float): Regularization parameter to prevent overfitting\n",
    "    \n",
    "    The EASE algorithm creates a self-expressiveness matrix that can reconstruct\n",
    "    the original user-item interaction matrix through a closed-form solution.\n",
    "    \"\"\"\n",
    "    # Convert user-item interactions to sparse tensor format\n",
    "    self.indices = torch.LongTensor(train[['userId', 'movieId']].values)\n",
    "    self.values = torch.ones(self.indices.shape[0])\n",
    "    self.sparse = torch.sparse.FloatTensor(self.indices.t(), self.values)\n",
    "    \n",
    "    # Convert sparse matrix to dense and compute Gram matrix\n",
    "    # G = X^T * X where X is the user-item interaction matrix\n",
    "    G = self.sparse.to_dense().t() @ self.sparse.to_dense()\n",
    "    \n",
    "    # Add regularization term (lambda * I) to the diagonal\n",
    "    # This helps prevent overfitting and ensures matrix invertibility\n",
    "    G += torch.eye(G.shape[0])*lambda_\n",
    "    \n",
    "    # Compute the closed-form solution\n",
    "    # P = (X^T * X + λI)^(-1)\n",
    "    P = G.inverse()\n",
    "    \n",
    "    # Calculate the self-expressiveness matrix B\n",
    "    # Normalize by the negative diagonal entries\n",
    "    self.B = P / (-1*P.diag())\n",
    "    \n",
    "    # Add identity matrix to prevent self-recommendation\n",
    "    # Final B matrix will have zeros on the diagonal\n",
    "    self.B = self.B + torch.eye(self.B.shape[0])\n",
    "  \n",
    "  def predict_all(self, pred_df: pd.DataFrame, k: int = 5, remove_owned: bool = True):\n",
    "    \"\"\"\n",
    "    Generate top-k recommendations for each user using the EASE model.\n",
    "    \n",
    "    Args:\n",
    "        pred_df (pd.DataFrame): DataFrame containing users for whom to generate predictions\n",
    "                              Must contain a 'userId' column\n",
    "        k (int): Number of recommendations to generate per user\n",
    "        remove_owned (bool): If True, penalizes items the user has already interacted with\n",
    "                           to avoid recommending them again\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of users + their predictions in sorted order\n",
    "    \"\"\"\n",
    "    # Keep only unique users from prediction DataFrame\n",
    "    pred_df = pred_df[['userId']].drop_duplicates()\n",
    "\n",
    "    # Store predictions for all users\n",
    "    _output_preds = []\n",
    "    \n",
    "    # Convert sparse user-item interaction matrix to dense format\n",
    "    # and select only the rows corresponding to users in pred_df\n",
    "    _user_tensor = self.sparse.to_dense().index_select(\n",
    "        dim=0, index=torch.LongTensor(pred_df['userId'].reset_index(drop=True))\n",
    "    )\n",
    "\n",
    "    # Generate predictions using the self-expressiveness matrix (B)\n",
    "    # _preds_tensor shape: [num_users x num_items]\n",
    "    # Each row contains predicted scores for all items for a user\n",
    "    _preds_tensor = _user_tensor @ self.B\n",
    "    \n",
    "    # If remove_owned is True, heavily penalize items the user has already interacted with\n",
    "    # by subtracting a large value (-10.0) from their prediction scores\n",
    "    if remove_owned:\n",
    "        _preds_tensor += -10.0 * _user_tensor\n",
    "\n",
    "    # For each user's predictions:\n",
    "    # 1. Get indices of top-k items with highest scores using torch.topk()\n",
    "    # 2. Convert to list and append to _output_preds\n",
    "    for _preds in _preds_tensor:\n",
    "        _output_preds.append(\n",
    "            [_id for _id in _preds.topk(k).indices.tolist()]\n",
    "        )\n",
    "\n",
    "    # Add predictions as a new column to the input DataFrame\n",
    "    pred_df[\"predicted_items\"] = _output_preds\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[19, 6, 141, 78, 32, 40, 143, 42, 16, 35, 50, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>[19, 34, 50, 8, 43, 99, 16, 30, 78, 33, 143, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>[31, 16, 50, 34, 99, 65, 40, 17, 1, 58, 78, 63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>[23, 6, 16, 99, 50, 42, 3, 141, 30, 33, 78, 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>[32, 16, 6, 30, 31, 65, 141, 143, 33, 78, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190558</th>\n",
       "      <td>11085</td>\n",
       "      <td>[23, 19, 34, 42, 6, 203, 85, 43, 8, 30, 31, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190574</th>\n",
       "      <td>11086</td>\n",
       "      <td>[23, 32, 43, 6, 3, 66, 19, 78, 50, 99, 10, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190585</th>\n",
       "      <td>11087</td>\n",
       "      <td>[99, 34, 6, 65, 42, 78, 32, 16, 196, 3, 210, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190598</th>\n",
       "      <td>11088</td>\n",
       "      <td>[19, 43, 32, 31, 6, 78, 8, 34, 30, 65, 16, 66,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190611</th>\n",
       "      <td>11089</td>\n",
       "      <td>[23, 19, 65, 31, 141, 40, 78, 3, 32, 143, 1, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId                                    predicted_items\n",
       "0            0  [19, 6, 141, 78, 32, 40, 143, 42, 16, 35, 50, ...\n",
       "13           1  [19, 34, 50, 8, 43, 99, 16, 30, 78, 33, 143, 1...\n",
       "27           2  [31, 16, 50, 34, 99, 65, 40, 17, 1, 58, 78, 63...\n",
       "42           3  [23, 6, 16, 99, 50, 42, 3, 141, 30, 33, 78, 55...\n",
       "57           4  [32, 16, 6, 30, 31, 65, 141, 143, 33, 78, 24, ...\n",
       "...        ...                                                ...\n",
       "190558   11085  [23, 19, 34, 42, 6, 203, 85, 43, 8, 30, 31, 3,...\n",
       "190574   11086  [23, 32, 43, 6, 3, 66, 19, 78, 50, 99, 10, 17,...\n",
       "190585   11087  [99, 34, 6, 65, 42, 78, 32, 16, 196, 3, 210, 8...\n",
       "190598   11088  [19, 43, 32, 31, 6, 78, 8, 34, 30, 65, 16, 66,...\n",
       "190611   11089  [23, 19, 65, 31, 141, 40, 78, 3, 32, 143, 1, 3...\n",
       "\n",
       "[11090 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ease = EASE(train, 2000)\n",
    "preds_ease = ease.predict_all(df, 100)\n",
    "\n",
    "preds_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from caserec.recommenders.item_recommendation.userknn import UserKNN\n",
    "from caserec.recommenders.item_recommendation.itemknn import ItemKNN\n",
    "from caserec.recommenders.item_recommendation.item_attribute_knn import ItemAttributeKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(movieId: int):\n",
    "    \"\"\"\n",
    "    Retrieve all tags associated with a specific movie.\n",
    "    \n",
    "    Args:\n",
    "        movieId (int): The ID of the movie to look up\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tags for the movie. Returns empty list if movie not found.\n",
    "        \n",
    "    Note:\n",
    "        Assumes existence of a global 'tags' DataFrame with columns 'movieId' and 'tag'\n",
    "    \"\"\"\n",
    "    # Check if movie exists in the tags dataset\n",
    "    if movieId not in tags['movieId'].values:\n",
    "        return []\n",
    "    # Return all tags associated with the movie as a list\n",
    "    return tags.loc[(tags.movieId==movieId),'tag'].tolist()\n",
    "\n",
    "def get_genres(movieId: int):\n",
    "    \"\"\"\n",
    "    Retrieve all genres associated with a specific movie.\n",
    "    \n",
    "    Args:\n",
    "        movieId (int): The ID of the movie to look up\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of genres for the movie. Returns empty list if movie not found\n",
    "             or if genres are not available (NA value).\n",
    "        \n",
    "    Note:\n",
    "        Assumes existence of a global 'movies' DataFrame with columns 'movieId' and 'genres'\n",
    "        Genres are expected to be stored as pipe-separated strings (e.g., \"Action|Adventure|Sci-Fi\")\n",
    "    \"\"\"\n",
    "    # Check if movie exists in the movies dataset\n",
    "    if movieId not in movies['movieId'].values:\n",
    "        return []  \n",
    "    \n",
    "    # Get the genre string for the movie\n",
    "    genre_str = movies.loc[movies['movieId'] == movieId, 'genres'].iloc[0]\n",
    "    # Split genre string by '|' if it exists, otherwise return empty list\n",
    "    return genre_str.split('|') if pd.notna(genre_str) else []\n",
    "\n",
    "def item_sim_jaccard(movieId1, movieId2, data_type='tag'):\n",
    "    \"\"\"\n",
    "    Calculate Jaccard similarity between two movies based on their tags or genres.\n",
    "    \n",
    "    Jaccard similarity = size of intersection / size of union\n",
    "    \n",
    "    Args:\n",
    "        movieId1 (int): ID of first movie\n",
    "        movieId2 (int): ID of second movie\n",
    "        data_type (str): Type of data to compare - either 'tag' or 'genre'\n",
    "    \n",
    "    Returns:\n",
    "        float: Jaccard similarity score between 0 and 1\n",
    "               0 = no overlap between tags/genres\n",
    "               1 = identical tags/genres\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If data_type is not 'tag' or 'genre'\n",
    "    \"\"\"\n",
    "    # Get appropriate lists based on data type\n",
    "    if data_type == 'tag':\n",
    "        list1 = get_tags(movieId1)  \n",
    "        list2 = get_tags(movieId2)\n",
    "    elif data_type == 'genre':\n",
    "        list1 = get_genres(movieId1)  \n",
    "        list2 = get_genres(movieId2)\n",
    "    else:\n",
    "        raise ValueError(\"data_type must be 'tag' ir 'genre'\")\n",
    "    \n",
    "    # Find common elements between the two lists\n",
    "    common_items = list(set(list1) & set(list2))\n",
    "    \n",
    "    # If no common items, similarity is 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate Jaccard similarity:\n",
    "    # Size of intersection divided by size of union\n",
    "    return len(common_items) / len(set(list1 + list2))\n",
    "\n",
    "def generate_sim_item_file(train: pd.DataFrame, method: str = 'tag'):\n",
    "    \"\"\"\n",
    "    Generate a similarity matrix file for all unique items (movies) in the training data.\n",
    "    The similarity is calculated using the Jaccard similarity coefficient based on either\n",
    "    tags or genres.\n",
    "    \n",
    "    Args:\n",
    "        train (pd.DataFrame): Training data containing movieId column\n",
    "        method (str): Method to calculate similarity - either 'tag' or 'genre'\n",
    "                     'tag': Uses movie tags for similarity calculation\n",
    "                     'genre': Uses movie genres for similarity calculation\n",
    "    \n",
    "    Outputs:\n",
    "        Creates a file 'sim_temp_matrix.dat' with format:\n",
    "        movieId1    movieId2    similarity_score\n",
    "        Each line represents the similarity between two movies.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If method is not 'tag' or 'genre'\n",
    "    \n",
    "    Note:\n",
    "        - Only calculates upper triangular matrix to avoid redundancy\n",
    "        - Assumes existence of item_sim_jaccard function\n",
    "        - Writes similarities in tab-separated format\n",
    "    \"\"\"\n",
    "    # Validate input method\n",
    "    if method not in ['tag', 'genre']:\n",
    "        raise ValueError(\"Method must be 'tag' or 'genre'\")\n",
    "    \n",
    "    # Get unique movies from training data\n",
    "    unique_items = train['movieId'].unique()\n",
    "    \n",
    "    # Open file in write mode to store similarity matrix\n",
    "    with open('sim_temp_matrix.dat', 'w') as arq_sim_matrix:\n",
    "        # Iterate through all unique pairs of movies\n",
    "        # Using i_idx + 1 in second loop to only compute upper triangular matrix\n",
    "        # This avoids redundant calculations since sim(i,j) = sim(j,i)\n",
    "        for i_idx, i in enumerate(unique_items):\n",
    "            for j in unique_items[i_idx + 1:]:\n",
    "                # Calculate Jaccard similarity between movies i and j\n",
    "                sim_score = item_sim_jaccard(i, j, method)\n",
    "                # Write result to file in format: movie1 movie2 similarity\n",
    "                arq_sim_matrix.write(f\"{i}\\t{j}\\t{sim_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos para comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Item Recommendation > UserKNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 405 items (152496 interactions) | sparsity:: 96.60%\n",
      "test data:: 10571 users and 331 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 11.534787 sec\n",
      "prediction_time:: 159.539348 sec\n",
      "\n",
      "\n",
      "Eval:: PREC@1: 0.445559 PREC@3: 0.319774 PREC@5: 0.263986 PREC@10: 0.190871 RECALL@1: 0.147543 RECALL@3: 0.297132 RECALL@5: 0.399217 RECALL@10: 0.562056 MAP@1: 0.445559 MAP@3: 0.537784 MAP@5: 0.53791 MAP@10: 0.505599 NDCG@1: 0.445559 NDCG@3: 0.624655 NDCG@5: 0.638181 NDCG@10: 0.627185 \n",
      "[Case Recommender: Item Recommendation > ItemKNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 405 items (152496 interactions) | sparsity:: 96.60%\n",
      "test data:: 10571 users and 331 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 0.549309 sec\n",
      "prediction_time:: 36.526676 sec\n",
      "\n",
      "\n",
      "Eval:: PREC@1: 0.422193 PREC@3: 0.307003 PREC@5: 0.252521 PREC@10: 0.187201 RECALL@1: 0.138504 RECALL@3: 0.285647 RECALL@5: 0.382874 RECALL@10: 0.552056 MAP@1: 0.422193 MAP@3: 0.514284 MAP@5: 0.517983 MAP@10: 0.489237 NDCG@1: 0.422193 NDCG@3: 0.602418 NDCG@5: 0.620641 NDCG@10: 0.614089 \n",
      "[Case Recommender: Item Recommendation > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 405 items (152496 interactions) | sparsity:: 96.60%\n",
      "test data:: 10571 users and 331 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 0.539245 sec\n",
      "prediction_time:: 35.725478 sec\n",
      "\n",
      "\n",
      "Eval:: PREC@1: 0.18494 PREC@3: 0.143001 PREC@5: 0.126819 PREC@10: 0.103245 RECALL@1: 0.057546 RECALL@3: 0.127693 RECALL@5: 0.18626 RECALL@10: 0.299896 MAP@1: 0.18494 MAP@3: 0.260106 MAP@5: 0.281135 MAP@10: 0.284305 NDCG@1: 0.18494 NDCG@3: 0.330627 NDCG@5: 0.373211 NDCG@10: 0.403937 \n",
      "[Case Recommender: Item Recommendation > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 405 items (152496 interactions) | sparsity:: 96.60%\n",
      "test data:: 10571 users and 331 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 0.313584 sec\n",
      "prediction_time:: 33.923710 sec\n",
      "\n",
      "\n",
      "Eval:: PREC@1: 0.114464 PREC@3: 0.100369 PREC@5: 0.089528 PREC@10: 0.076445 RECALL@1: 0.032414 RECALL@3: 0.085718 RECALL@5: 0.127635 RECALL@10: 0.21629 MAP@1: 0.114464 MAP@3: 0.17768 MAP@5: 0.196127 MAP@10: 0.206947 NDCG@1: 0.114464 NDCG@3: 0.237334 NDCG@5: 0.274977 NDCG@10: 0.313094 \n"
     ]
    }
   ],
   "source": [
    "class Base_Knn:\n",
    "    \"\"\"\n",
    "    Base class for KNN-based recommendation algorithms.\n",
    "    Handles common functionality like file management and recommendation generation.\n",
    "    \"\"\"\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, rank_length: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize base KNN recommender.\n",
    "        \n",
    "        Args:\n",
    "            train (pd.DataFrame): Training data with user-item interactions\n",
    "            test (pd.DataFrame): Test data for prediction\n",
    "            rank_length (int): Number of recommendations to generate per user\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.rank_length = rank_length\n",
    "        # Temporary file paths for external KNN computations\n",
    "        self.train_file = 'train_temp.dat'\n",
    "        self.test_file = 'test_temp.dat'\n",
    "        self.output_file = 'rec_temp.dat'\n",
    "    \n",
    "    def save_temp_files(self):\n",
    "        \"\"\"Save training and test data to temporary files in tab-separated format.\"\"\"\n",
    "        self.train.to_csv(self.train_file, index=False, header=False, sep='\\t')\n",
    "        self.test.to_csv(self.test_file, index=False, header=False, sep='\\t')\n",
    "    \n",
    "    def cleanup_temp_files(self, additional_files=None):\n",
    "        \"\"\"\n",
    "        Remove temporary files after computation.\n",
    "        \n",
    "        Args:\n",
    "            additional_files (list): Optional list of additional files to remove\n",
    "        \"\"\"\n",
    "        temp_files = [self.train_file, self.test_file, self.output_file]\n",
    "        if additional_files:\n",
    "            temp_files.extend(additional_files)\n",
    "        for file in temp_files:\n",
    "            if os.path.exists(file):\n",
    "                os.remove(file)\n",
    "    \n",
    "    def read_predictions(self):\n",
    "        \"\"\"\n",
    "        Read and sort KNN predictions from output file.\n",
    "        Returns sorted DataFrame with user, movie, and rating predictions.\n",
    "        \"\"\"\n",
    "        pred_knn = pd.read_csv(self.output_file, sep='\\t', names=['userId', 'movieId', 'relative_rating'])\n",
    "        pred_knn = pred_knn.sort_values(by=['userId', 'relative_rating'], ascending=[True, False])\n",
    "        return pred_knn\n",
    "\n",
    "    def generate_recommendations(self, pred_knn, pred_df):\n",
    "        \"\"\"\n",
    "        Generate final recommendations list for each user.\n",
    "        \n",
    "        Args:\n",
    "            pred_knn (pd.DataFrame): Raw predictions from KNN\n",
    "            pred_df (pd.DataFrame): DataFrame with user IDs to generate recommendations for\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with user IDs and their recommended items\n",
    "        \"\"\"\n",
    "        pred_items = pred_knn.groupby('userId')['movieId'].apply(list).reset_index()\n",
    "        pred_items.rename(columns={'movieId': 'predicted_items'}, inplace=True)\n",
    "        pred_df = pred_df[['userId']].drop_duplicates()\n",
    "        pred_df = pred_df.merge(pred_items, on='userId', how='left')\n",
    "        return pred_df\n",
    "\n",
    "class User_Knn(Base_Knn):\n",
    "    \"\"\"\n",
    "    User-based KNN recommender system.\n",
    "    Finds similar users based on their rating patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, similarity_metric: str = 'cosine', rank_length: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            similarity_metric (str): Method to compute user similarity (e.g., 'cosine')\n",
    "        \"\"\"\n",
    "        super().__init__(train, test, rank_length)\n",
    "        self.similarity_metric = similarity_metric\n",
    "\n",
    "    def predict_all(self, pred_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate recommendations using user-based KNN approach.\n",
    "        \"\"\"\n",
    "        self.save_temp_files()\n",
    "        UserKNN(train_file=self.train_file, test_file=self.test_file, output_file=self.output_file,\n",
    "                similarity_metric=self.similarity_metric, rank_length=self.rank_length\n",
    "                ).compute(verbose=True, verbose_evaluation=True)\n",
    "        pred_knn = self.read_predictions()\n",
    "        result = self.generate_recommendations(pred_knn, pred_df)\n",
    "        self.cleanup_temp_files()\n",
    "        return result\n",
    "\n",
    "class Item_Knn(Base_Knn):\n",
    "    \"\"\"\n",
    "    Item-based KNN recommender system.\n",
    "    Finds similar items based on user rating patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, similarity_metric: str = 'cosine', rank_length: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            similarity_metric (str): Method to compute item similarity (e.g., 'cosine')\n",
    "        \"\"\"\n",
    "        super().__init__(train, test, rank_length)\n",
    "        self.similarity_metric = similarity_metric\n",
    "\n",
    "    def predict_all(self, pred_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate recommendations using item-based KNN approach.\n",
    "        \"\"\"\n",
    "        self.save_temp_files()\n",
    "        ItemKNN(train_file=self.train_file, test_file=self.test_file, output_file=self.output_file,\n",
    "                similarity_metric=self.similarity_metric, rank_length=self.rank_length\n",
    "                ).compute(verbose=True, verbose_evaluation=True)\n",
    "        pred_knn = self.read_predictions()\n",
    "        result = self.generate_recommendations(pred_knn, pred_df)\n",
    "        self.cleanup_temp_files()\n",
    "        return result\n",
    "\n",
    "class ItemAttribute_Knn(Base_Knn):\n",
    "    \"\"\"\n",
    "    Item-attribute based KNN recommender system.\n",
    "    Finds similar items based on specific item attributes (e.g., genre, tags).\n",
    "    \"\"\"\n",
    "    def __init__(self, train: pd.DataFrame, test: pd.DataFrame, attribute: str, rank_length: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            attribute (str): Item attribute to use for similarity computation\n",
    "        \"\"\"\n",
    "        super().__init__(train, test, rank_length)\n",
    "        self.attribute = attribute\n",
    "        self.similarity_file = 'sim_temp_matrix.dat'\n",
    "\n",
    "    def predict_all(self, pred_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate recommendations using item-attribute based KNN approach.\n",
    "        Uses external similarity matrix generation and ItemAttributeKNN implementation.\n",
    "        \"\"\"\n",
    "        self.save_temp_files()\n",
    "        # Generate similarity matrix based on specified attribute\n",
    "        generate_sim_item_file(train=self.train, method=self.attribute)\n",
    "        ItemAttributeKNN(train_file=self.train_file, test_file=self.test_file, output_file=self.output_file,\n",
    "                         similarity_file=self.similarity_file, rank_length=self.rank_length\n",
    "                         ).compute(verbose=True, verbose_evaluation=True)\n",
    "        pred_knn = self.read_predictions()\n",
    "        result = self.generate_recommendations(pred_knn, pred_df)\n",
    "        self.cleanup_temp_files(additional_files=[self.similarity_file])\n",
    "        return result\n",
    "\n",
    "userknn = User_Knn(train = train[['userId', 'movieId', 'rating']], test = test[['userId', 'movieId', 'rating']], rank_length = 100).predict_all(df)\n",
    "itemknn = Item_Knn(train = train[['userId', 'movieId', 'rating']], test = test[['userId', 'movieId', 'rating']], rank_length = 100).predict_all(df)\n",
    "itemattribute_tag = ItemAttribute_Knn(train = train[['userId', 'movieId', 'rating']], test = test[['userId', 'movieId', 'rating']], attribute = 'tag', rank_length = 100).predict_all(df)\n",
    "itemattribute_genre = ItemAttribute_Knn(train = train[['userId', 'movieId', 'rating']], test = test[['userId', 'movieId', 'rating']], attribute = 'genre', rank_length = 100).predict_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[507, 1211, 1158, 706, 902, 398, 958, 615, 964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[2226, 6315, 4137, 3638, 314, 4800, 461, 510, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[224, 915, 898, 510, 911, 418, 507, 900, 1939,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2250, 1939, 2195, 900, 224, 836, 659, 964, 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[277, 509, 395, 314, 418, 123, 138, 334, 249, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>[277, 3141, 2982, 1267, 2302, 2145, 1398, 1071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>[900, 2078, 902, 0, 546, 510, 314, 1067, 334, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>[615, 1158, 4800, 2078, 863, 224, 1734, 314, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>[307, 337, 302, 138, 126, 43, 506, 510, 253, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>[900, 4159, 1183, 6315, 659, 510, 1734, 1576, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId                                    predicted_items\n",
       "0         0  [507, 1211, 1158, 706, 902, 398, 958, 615, 964...\n",
       "1         1  [2226, 6315, 4137, 3638, 314, 4800, 461, 510, ...\n",
       "2         2  [224, 915, 898, 510, 911, 418, 507, 900, 1939,...\n",
       "3         3  [2250, 1939, 2195, 900, 224, 836, 659, 964, 96...\n",
       "4         4  [277, 509, 395, 314, 418, 123, 138, 334, 249, ...\n",
       "..      ...                                                ...\n",
       "605     605  [277, 3141, 2982, 1267, 2302, 2145, 1398, 1071...\n",
       "606     606  [900, 2078, 902, 0, 546, 510, 314, 1067, 334, ...\n",
       "607     607  [615, 1158, 4800, 2078, 863, 224, 1734, 314, 9...\n",
       "608     608  [307, 337, 302, 138, 126, 43, 506, 510, 253, 2...\n",
       "609     609  [900, 4159, 1183, 6315, 659, 510, 1734, 1576, ...\n",
       "\n",
       "[610 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[902, 1158, 793, 1211, 964, 1979, 2078, 507, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[8063, 8990, 8372, 7090, 6331, 6534, 8879, 674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[681, 2764, 2248, 1273, 786, 2636, 789, 2978, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[520, 659, 224, 828, 923, 705, 907, 964, 900, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[509, 123, 505, 334, 436, 418, 314, 156, 472, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>[898, 2145, 3141, 964, 1267, 4360, 1298, 3568,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>[900, 1067, 902, 969, 334, 0, 899, 314, 2078, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>[1158, 2078, 939, 2038, 314, 224, 337, 418, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>[337, 126, 138, 307, 302, 334, 253, 275, 322, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>[3614, 3194, 6315, 4159, 6346, 900, 8681, 3006...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId                                    predicted_items\n",
       "0         0  [902, 1158, 793, 1211, 964, 1979, 2078, 507, 5...\n",
       "1         1  [8063, 8990, 8372, 7090, 6331, 6534, 8879, 674...\n",
       "2         2  [681, 2764, 2248, 1273, 786, 2636, 789, 2978, ...\n",
       "3         3  [520, 659, 224, 828, 923, 705, 907, 964, 900, ...\n",
       "4         4  [509, 123, 505, 334, 436, 418, 314, 156, 472, ...\n",
       "..      ...                                                ...\n",
       "605     605  [898, 2145, 3141, 964, 1267, 4360, 1298, 3568,...\n",
       "606     606  [900, 1067, 902, 969, 334, 0, 899, 314, 2078, ...\n",
       "607     607  [1158, 2078, 939, 2038, 314, 224, 337, 418, 86...\n",
       "608     608  [337, 126, 138, 307, 302, 334, 253, 275, 322, ...\n",
       "609     609  [3614, 3194, 6315, 4159, 6346, 900, 8681, 3006...\n",
       "\n",
       "[610 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[19, 1, 141, 6, 58, 42, 33, 126, 40, 3, 129, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[19, 141, 1, 37, 273, 126, 196, 35, 33, 58, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 141, 31, 126, 223, 17, 85, 58, 51, 196, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 37, 141, 6, 273, 196, 126, 23, 7, 123, 85,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[37, 32, 1, 126, 141, 196, 33, 223, 65, 35, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>11085</td>\n",
       "      <td>[42, 19, 1, 196, 35, 23, 37, 8, 6, 123, 24, 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>11086</td>\n",
       "      <td>[32, 19, 141, 37, 223, 273, 17, 6, 126, 64, 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>11087</td>\n",
       "      <td>[1, 37, 196, 8, 33, 171, 126, 65, 32, 223, 42,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>11088</td>\n",
       "      <td>[1, 141, 120, 32, 42, 115, 19, 273, 33, 65, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>11089</td>\n",
       "      <td>[19, 23, 40, 58, 126, 1, 120, 31, 143, 360, 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId                                    predicted_items\n",
       "0           0  [19, 1, 141, 6, 58, 42, 33, 126, 40, 3, 129, 1...\n",
       "1           1  [19, 141, 1, 37, 273, 126, 196, 35, 33, 58, 12...\n",
       "2           2  [1, 141, 31, 126, 223, 17, 85, 58, 51, 196, 17...\n",
       "3           3  [1, 37, 141, 6, 273, 196, 126, 23, 7, 123, 85,...\n",
       "4           4  [37, 32, 1, 126, 141, 196, 33, 223, 65, 35, 44...\n",
       "...       ...                                                ...\n",
       "11085   11085  [42, 19, 1, 196, 35, 23, 37, 8, 6, 123, 24, 64...\n",
       "11086   11086  [32, 19, 141, 37, 223, 273, 17, 6, 126, 64, 85...\n",
       "11087   11087  [1, 37, 196, 8, 33, 171, 126, 65, 32, 223, 42,...\n",
       "11088   11088  [1, 141, 120, 32, 42, 115, 19, 273, 33, 65, 24...\n",
       "11089   11089  [19, 23, 40, 58, 126, 1, 120, 31, 143, 360, 12...\n",
       "\n",
       "[11090 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemattribute_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[129, 141, 35, 126, 62, 1, 4, 20, 86, 109, 160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[37, 64, 109, 19, 126, 223, 62, 127, 35, 53, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[17, 127, 62, 115, 223, 1, 4, 20, 86, 89, 126,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 4, 20, 86, 160, 171, 17, 127, 37, 126, 42,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[32, 62, 1, 4, 20, 86, 126, 160, 171, 196, 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>11085</td>\n",
       "      <td>[127, 17, 58, 42, 8, 30, 6, 37, 22, 23, 25, 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>11086</td>\n",
       "      <td>[32, 127, 17, 244, 247, 223, 37, 66, 89, 181, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>11087</td>\n",
       "      <td>[8, 30, 127, 53, 17, 32, 44, 125, 181, 244, 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>11088</td>\n",
       "      <td>[109, 273, 53, 62, 6, 51, 52, 171, 235, 58, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>11089</td>\n",
       "      <td>[141, 1, 4, 20, 86, 160, 171, 223, 129, 19, 62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId                                    predicted_items\n",
       "0           0  [129, 141, 35, 126, 62, 1, 4, 20, 86, 109, 160...\n",
       "1           1  [37, 64, 109, 19, 126, 223, 62, 127, 35, 53, 1...\n",
       "2           2  [17, 127, 62, 115, 223, 1, 4, 20, 86, 89, 126,...\n",
       "3           3  [1, 4, 20, 86, 160, 171, 17, 127, 37, 126, 42,...\n",
       "4           4  [32, 62, 1, 4, 20, 86, 126, 160, 171, 196, 123...\n",
       "...       ...                                                ...\n",
       "11085   11085  [127, 17, 58, 42, 8, 30, 6, 37, 22, 23, 25, 51...\n",
       "11086   11086  [32, 127, 17, 244, 247, 223, 37, 66, 89, 181, ...\n",
       "11087   11087  [8, 30, 127, 53, 17, 32, 44, 125, 181, 244, 58...\n",
       "11088   11088  [109, 273, 53, 62, 6, 51, 52, 171, 235, 58, 14...\n",
       "11089   11089  [141, 1, 4, 20, 86, 160, 171, 223, 129, 19, 62...\n",
       "\n",
       "[11090 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemattribute_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(user: int, test: pd.DataFrame, user_recommendations: list, limit: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Average Precision (AP) for a single user's recommendations.\n",
    "    AP measures the average of precision values at each relevant item in the ranked list.\n",
    "    \n",
    "    Args:\n",
    "        user (int): User ID to evaluate\n",
    "        test (pd.DataFrame): Ground truth data containing actual user-item interactions\n",
    "        user_recommendations (list): Ordered list of recommended items for the user\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: Average Precision score (0-1)\n",
    "    \"\"\"\n",
    "    # Get actual items the user interacted with (ground truth)\n",
    "    ground_truth = test.loc[(test.userId==user), 'movieId'].tolist()\n",
    "    total = 0  # Number of items examined\n",
    "    hits = 0   # Number of relevant items found\n",
    "    ap = 0.0   # Running sum of precision values\n",
    "    \n",
    "    # Calculate precision at each position in recommendations\n",
    "    for val in user_recommendations:\n",
    "        total += 1\n",
    "        if val in ground_truth:  # If recommendation is relevant\n",
    "            hits += 1\n",
    "            ap += hits / total   # Add precision at this position\n",
    "        if total == limit:       # Stop after examining k items\n",
    "            break\n",
    "            \n",
    "    # Normalize by number of hits (relevant items found)\n",
    "    if hits:\n",
    "        ap /= hits\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(test: pd.DataFrame, recommendations: pd.DataFrame, limit: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP) across all users.\n",
    "    MAP is the mean of Average Precision scores for all users.\n",
    "    \n",
    "    Args:\n",
    "        test (pd.DataFrame): Ground truth data\n",
    "        recommendations (pd.DataFrame): DataFrame with user recommendations\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: MAP score (0-1)\n",
    "    \"\"\"\n",
    "    mean_avg_precision = 0.0\n",
    "    users = list(map_users.values())\n",
    "    \n",
    "    # Calculate AP for each user and sum\n",
    "    for user in users:\n",
    "        mean_avg_precision += average_precision(\n",
    "            user, \n",
    "            test, \n",
    "            recommendations.loc[(recommendations.userId == user), 'predicted_items'].values[0], \n",
    "            limit\n",
    "        )\n",
    "    \n",
    "    # Return average across all users\n",
    "    return mean_avg_precision / len(users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(user: int, test: pd.DataFrame, user_recommendations: list, limit: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Recall for a single user's recommendations.\n",
    "    Recall measures the fraction of relevant items that are successfully retrieved.\n",
    "    \n",
    "    Args:\n",
    "        user (int): User ID to evaluate\n",
    "        test (pd.DataFrame): Ground truth data\n",
    "        user_recommendations (list): Ordered list of recommended items\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: Recall score (0-1)\n",
    "    \"\"\"\n",
    "    # Get ground truth items\n",
    "    ground_truth = test.loc[(test.userId==user), 'movieId'].tolist()\n",
    "    \n",
    "    # Find all relevant items in recommendations\n",
    "    relevant = list(set(user_recommendations) & set(ground_truth))\n",
    "    if len(relevant) == 0:  # If user has no relevant items\n",
    "        return 0.0\n",
    "    \n",
    "    # Find relevant items in top-k recommendations\n",
    "    relevant_k = list(set(user_recommendations[:limit]) & set(ground_truth))\n",
    "    \n",
    "    # Return fraction of all relevant items found in top-k\n",
    "    return len(relevant_k) / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_recall(test: pd.DataFrame, recommendations: pd.DataFrame, limit: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Recall across all users.\n",
    "    \n",
    "    Args:\n",
    "        test (pd.DataFrame): Ground truth data\n",
    "        recommendations (pd.DataFrame): DataFrame with user recommendations\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Recall score (0-1)\n",
    "    \"\"\"\n",
    "    mean_recall = 0.0\n",
    "    users = list(map_users.values())\n",
    "    \n",
    "    # Calculate recall for each user and sum\n",
    "    for user in users:\n",
    "        mean_recall += recall(\n",
    "            user, \n",
    "            test, \n",
    "            recommendations.loc[(recommendations.userId == user), 'predicted_items'].values[0], \n",
    "            limit\n",
    "        )\n",
    "    \n",
    "    # Return average across all users\n",
    "    return mean_recall / len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(user: int, test: pd.DataFrame, user_recommendations: list, limit: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Precision for a single user's recommendations.\n",
    "    Precision measures the fraction of recommended items that are relevant.\n",
    "    \n",
    "    Args:\n",
    "        user (int): User ID to evaluate\n",
    "        test (pd.DataFrame): Ground truth data\n",
    "        user_recommendations (list): Ordered list of recommended items\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: Precision score (0-1)\n",
    "    \"\"\"\n",
    "    ground_truth = test.loc[(test.userId==user), 'movieId'].tolist()\n",
    "    total = 0  # Number of recommendations examined\n",
    "    hits = 0   # Number of relevant recommendations\n",
    "    \n",
    "    # Count relevant items in top-k recommendations\n",
    "    for val in user_recommendations:\n",
    "        total += 1\n",
    "        if val in ground_truth:\n",
    "            hits += 1\n",
    "        if total == limit:\n",
    "            break\n",
    "            \n",
    "    return hits/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_precision(test: pd.DataFrame, recommendations: pd.DataFrame, limit: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Precision across all users.\n",
    "    \n",
    "    Args:\n",
    "        test (pd.DataFrame): Ground truth data\n",
    "        recommendations (pd.DataFrame): DataFrame with user recommendations\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean Precision score (0-1)\n",
    "    \"\"\"\n",
    "    mean_precision = 0.0\n",
    "    users = list(map_users.values())\n",
    "    \n",
    "    # Calculate precision for each user and sum\n",
    "    for user in users:\n",
    "        mean_precision += precision(\n",
    "            user, \n",
    "            test, \n",
    "            recommendations.loc[(recommendations.userId == user), 'predicted_items'].values[0], \n",
    "            limit\n",
    "        )\n",
    "    \n",
    "    # Return average across all users\n",
    "    return mean_precision / len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(user: int, test: pd.DataFrame, user_recommendations: list, limit: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Normalized Discounted Cumulative Gain (NDCG) for a single user's recommendations.\n",
    "    NDCG measures the quality of ranking by incorporating position-dependent weights.\n",
    "    \n",
    "    Args:\n",
    "        user (int): User ID to evaluate\n",
    "        test (pd.DataFrame): Ground truth data containing actual user-item interactions\n",
    "        user_recommendations (list): Ordered list of recommended items for the user\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: NDCG score (0-1)\n",
    "        - 0 means poor ranking quality\n",
    "        - 1 means perfect ranking\n",
    "    \"\"\"\n",
    "    # Get actual items the user interacted with (ground truth)\n",
    "    ground_truth = test.loc[(test.userId==user), 'movieId'].tolist()\n",
    "    \n",
    "    total = 0  # Number of items examined\n",
    "    hits = 0   # Number of relevant items found\n",
    "    dcg = 0.0  # Discounted Cumulative Gain\n",
    "    \n",
    "    # Calculate DCG\n",
    "    for val in user_recommendations:\n",
    "        total += 1\n",
    "        if val in ground_truth:\n",
    "            hits += 1\n",
    "            # Add position-discounted gain\n",
    "            # Position is (total + 1) because log2(1) = 0\n",
    "            dcg += 1 / (np.log2(total + 1))\n",
    "        if total == limit:\n",
    "            break\n",
    "    \n",
    "    # If no relevant items found, NDCG is 0\n",
    "    if hits == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Calculate Ideal DCG (IDCG)\n",
    "    # IDCG is DCG score for perfect ranking where all relevant items appear first\n",
    "    idcg = 0.0\n",
    "    for i in range(hits):\n",
    "        # i+2 because position starts at 1 and we need log2(position)\n",
    "        idcg += 1 / (np.log2(i+2))\n",
    "    \n",
    "    # Return normalized score (DCG/IDCG)\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ndcg(test: pd.DataFrame, recommendations: pd.DataFrame, limit: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean NDCG across all users.\n",
    "    \n",
    "    Args:\n",
    "        test (pd.DataFrame): Ground truth data\n",
    "        recommendations (pd.DataFrame): DataFrame with user recommendations\n",
    "        limit (int): Number of recommendations to consider (k)\n",
    "    \n",
    "    Returns:\n",
    "        float: Mean NDCG score (0-1)\n",
    "    \"\"\"\n",
    "    mean_ndcg = 0.0\n",
    "    users = list(map_users.values())\n",
    "    \n",
    "    # Calculate NDCG for each user and sum\n",
    "    for user in users:\n",
    "        mean_ndcg += ndcg(\n",
    "            user, \n",
    "            test, \n",
    "            recommendations.loc[(recommendations.userId == user), 'predicted_items'].values[0], \n",
    "            limit\n",
    "        )\n",
    "    \n",
    "    # Return average across all users\n",
    "    return mean_ndcg / len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[19, 6, 141, 40, 78, 32, 143, 42, 35, 203, 50,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>[19, 50, 34, 8, 43, 30, 99, 16, 33, 78, 143, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>[31, 16, 50, 34, 99, 65, 40, 1, 17, 63, 58, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>[23, 6, 16, 99, 50, 42, 3, 141, 33, 55, 30, 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>[32, 16, 6, 30, 31, 65, 33, 141, 143, 78, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190558</th>\n",
       "      <td>11085</td>\n",
       "      <td>[23, 19, 34, 6, 42, 203, 85, 8, 43, 30, 31, 66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190574</th>\n",
       "      <td>11086</td>\n",
       "      <td>[23, 32, 43, 6, 66, 3, 78, 19, 50, 99, 10, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190585</th>\n",
       "      <td>11087</td>\n",
       "      <td>[99, 34, 6, 42, 65, 78, 32, 16, 210, 196, 3, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190598</th>\n",
       "      <td>11088</td>\n",
       "      <td>[43, 19, 32, 31, 6, 78, 8, 65, 30, 34, 66, 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190611</th>\n",
       "      <td>11089</td>\n",
       "      <td>[23, 19, 65, 31, 40, 141, 78, 1, 143, 3, 58, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId                                    predicted_items\n",
       "0            0  [19, 6, 141, 40, 78, 32, 143, 42, 35, 203, 50,...\n",
       "13           1  [19, 50, 34, 8, 43, 30, 99, 16, 33, 78, 143, 1...\n",
       "27           2  [31, 16, 50, 34, 99, 65, 40, 1, 17, 63, 58, 4,...\n",
       "42           3  [23, 6, 16, 99, 50, 42, 3, 141, 33, 55, 30, 37...\n",
       "57           4  [32, 16, 6, 30, 31, 65, 33, 141, 143, 78, 40, ...\n",
       "...        ...                                                ...\n",
       "190558   11085  [23, 19, 34, 6, 42, 203, 85, 8, 43, 30, 31, 66...\n",
       "190574   11086  [23, 32, 43, 6, 66, 3, 78, 19, 50, 99, 10, 17,...\n",
       "190585   11087  [99, 34, 6, 42, 65, 78, 32, 16, 210, 196, 3, 2...\n",
       "190598   11088  [43, 19, 32, 31, 6, 78, 8, 65, 30, 34, 66, 10,...\n",
       "190611   11089  [23, 19, 65, 31, 40, 141, 78, 1, 143, 3, 58, 3...\n",
       "\n",
       "[11090 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>RECALL@10</th>\n",
       "      <th>PRECISION@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EASE</td>\n",
       "      <td>0.507238</td>\n",
       "      <td>0.172833</td>\n",
       "      <td>0.298689</td>\n",
       "      <td>0.614132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_knn</td>\n",
       "      <td>0.446242</td>\n",
       "      <td>0.165572</td>\n",
       "      <td>0.266393</td>\n",
       "      <td>0.566522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_knn</td>\n",
       "      <td>0.484428</td>\n",
       "      <td>0.158720</td>\n",
       "      <td>0.284262</td>\n",
       "      <td>0.595014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    MAP@10  RECALL@10  PRECISION@10   NDCG@10\n",
       "0      EASE  0.507238   0.172833      0.298689  0.614132\n",
       "1  user_knn  0.446242   0.165572      0.266393  0.566522\n",
       "2  item_knn  0.484428   0.158720      0.284262  0.595014"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary mapping recommendation method names to their prediction DataFrames\n",
    "methods = {\n",
    "    \"EASE\": preds_ease,\n",
    "    \"user_knn\": userknn,\n",
    "    \"item_knn\": itemknn,\n",
    "    \"itemattribute_tag\": itemattribute_tag,\n",
    "    \"itemattribute_genre\": itemattribute_genre\n",
    "}\n",
    "    \n",
    "# List to store evaluation metrics for each recommendation method\n",
    "results = []\n",
    "\n",
    "# Iterate through each recommendation method and its predictions\n",
    "for method_name, recommendation_df in methods.items():\n",
    "    # Calculate Mean Average Precision at K=10\n",
    "    map_score = mean_average_precision(test, recommendation_df, 10)\n",
    "    # Calculate Recall at K=10\n",
    "    recall_score = mean_recall(test, recommendation_df, 10)\n",
    "    # Calculate Precision at K=10\n",
    "    precision_score = mean_precision(test, recommendation_df, 10)\n",
    "    # Calculate Normalized Discounted Cumulative Gain at K=10\n",
    "    ndcg_score = mean_ndcg(test, recommendation_df, 10)\n",
    "\n",
    "    # Store results for current method in a dictionary\n",
    "    results.append({\n",
    "        \"method\": method_name,\n",
    "        \"MAP@10\": map_score,\n",
    "        \"RECALL@10\": recall_score,\n",
    "        \"PRECISION@10\": precision_score,\n",
    "        \"NDCG@10\": ndcg_score\n",
    "    })\n",
    "\n",
    "# Convert results list to a pandas DataFrame for easier comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "# Display the results DataFrame showing performance metrics for all methods\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
